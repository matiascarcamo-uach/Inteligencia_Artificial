{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 7: Algoritmo Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook está basado en el <a href=\"https://stackabuse.com/random-forest-algorithm-with-python-and-scikit-learn/\"> tutorial</a> propuesto por <a href=\"https://twitter.com/usman_malikk\"> Usman Malik</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Random forest</b> es un tipo de algoritmo de aprendizaje supervisado de máquinas basado en el aprendizaje de conjuntos (Ensemble Learning). <b>Ensemble Learning</b> es un tipo de aprendizaje en el que se unen diferentes tipos de algoritmos o el mismo algoritmo varias veces para formar un modelo de predicción más potente. El algoritmo Random Forest combina múltiples árboles de decisión, dando como resultado un bosque de árboles, de ahí el nombre \"Random Forest\". Random Forest puede utilizarse tanto para tareas de <b>regresión</b> como de <b>clasificación</b>. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ¿Cómo funciona el algoritmo Random Forest?\n",
    "\n",
    "Random Forest se divide en 3 pasos básicos:\n",
    "\n",
    "- Seleccione N registros aleatorios del conjunto de datos.\n",
    "- Construya un árbol de decisión basado en estos registros N. (ver <i>Notebook 6</i>)\n",
    "- Elija el número de árboles que desee en su algoritmo y repita los pasos 1 y 2.\n",
    "\n",
    "En caso de un <b>problema de regresión</b>, para una nueva observación, cada árbol en el bosque predice un valor para Y (salida). El valor final puede ser calculado tomando el promedio de todos los valores pronosticados por todos los árboles en el bosque. \n",
    "\n",
    "En caso de un <b>problema de clasificación</b>, cada árbol del bosque predice la categoría a la que pertenece la nueva observación. Finalmente, la nueva observación se asigna a la categoría que gana la mayoría de los votos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ventaja y Desventaja de usar Random Forest\n",
    "\n",
    "Los bosques aleatorios son un método poderoso con varias ventajas:\n",
    "\n",
    "- Tanto el entrenamiento como la predicción son muy rápidos, debido a la simplicidad de los árboles de decisión subyacentes. Además, ambas tareas pueden ser directamente paralelizadas, ya que los árboles individuales son entidades totalmente independientes.\n",
    "- Los múltiples árboles permiten una clasificación probabilística: un voto mayoritario entre los estimadores da una estimación de la probabilidad (accedido en Scikit-Learn con el método predict_proba()).\n",
    "\n",
    "Una desventaja principal de los bosques aleatorios es que los resultados no son fácilmente interpretables: es decir, si se desea sacar conclusiones sobre el significado del modelo de clasificación, los bosques aleatorios pueden no ser la mejor opción.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Ejemplo de Uso de Random Forest para la regresión\n",
    "\n",
    "En esta sección estudiaremos cómo los bosques aleatorios pueden ser utilizados para resolver problemas de regresión usando Scikit-Learn. En la siguiente sección resolveremos el problema de la clasificación a través de bosques aleatorios.\n",
    "\n",
    "#### Definición del problema\n",
    "\n",
    "El problema aquí es predecir el consumo de gasolina (en millones de galones) en 48 de los estados de los EE.UU. basado en el impuesto a la gasolina (en centavos), el ingreso per cápita (dólares), las carreteras pavimentadas (en millas) y la proporción de la población con la licencia de conducir.\n",
    "\n",
    "#### Solución\n",
    "\n",
    "Para resolver este problema de regresión usaremos el algoritmo de bosque aleatorio a través de la biblioteca Scikit-Learn Python. Seguiremos el proceso de aprendizaje tradicional de la máquina para resolver este problema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a - Importar y Preparar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Petrol_tax</th>\n",
       "      <th>Average_income</th>\n",
       "      <th>Paved_Highways</th>\n",
       "      <th>Population_Driver_licence(%)</th>\n",
       "      <th>Petrol_Consumption</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3571</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.525</td>\n",
       "      <td>541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>4092</td>\n",
       "      <td>1250</td>\n",
       "      <td>0.572</td>\n",
       "      <td>524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>3865</td>\n",
       "      <td>1586</td>\n",
       "      <td>0.580</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.5</td>\n",
       "      <td>4870</td>\n",
       "      <td>2351</td>\n",
       "      <td>0.529</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>4399</td>\n",
       "      <td>431</td>\n",
       "      <td>0.544</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Petrol_tax  Average_income  Paved_Highways  Population_Driver_licence(%)  \\\n",
       "0         9.0            3571            1976                         0.525   \n",
       "1         9.0            4092            1250                         0.572   \n",
       "2         9.0            3865            1586                         0.580   \n",
       "3         7.5            4870            2351                         0.529   \n",
       "4         8.0            4399             431                         0.544   \n",
       "\n",
       "   Petrol_Consumption  \n",
       "0                 541  \n",
       "1                 524  \n",
       "2                 561  \n",
       "3                 414  \n",
       "4                 410  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARGAR EL DATASET\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "\n",
    "dataset = pd.read_csv('petrol_consumption.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La primera tarea es dividir los datos en conjuntos de'atributos' y'etiquetas'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir Features y Labels\n",
    "X = dataset.iloc[:, 0:4].values  \n",
    "y = dataset.iloc[:, 4].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, dividamos los datos en conjuntos de entrenamiento y pruebas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b - Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "           oob_score=False, random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=1)  \n",
    "regressor.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase <code>RandomForestRegressor</code> de la biblioteca <code>sklearn.ensemble</code> se utiliza para resolver problemas de regresión. El parámetro más importante de la clase <code>RandomForestRegressor</code> es el parámetro <code>n_estimators</code>. Este parámetro define el número de árboles en el bosque aleatorio. Comenzaremos con <code>n_estimator=20</code> para ver cómo funciona nuestro algoritmo. Puede encontrar detalles de todos los parámetros de RandomForestRegressor <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\">aquí</a>.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c - Evaluación del modelo Random Forest\n",
    "\n",
    "Para los problemas de regresión, las métricas frecuentemente utilizadas para evaluar un modelo son el error absoluto medio, el error al cuadrado medio y el error al cuadrado medio de la raíz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = regressor.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 47.864999999999995\n",
      "Mean Squared Error: 3422.699249999999\n",
      "Root Mean Squared Error: 58.50383961758407\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))  \n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))  \n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Consultas</b>:\n",
    "- ¿Cuál valor de <code>n_estimator</code> permite optimizar el RMSE?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 56.29958000139373\n"
     ]
    }
   ],
   "source": [
    "rmse = []\n",
    "menor = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "for estimator in range(1,50):\n",
    "    regressor = RandomForestRegressor(n_estimators=estimator, random_state=1)\n",
    "    regressor.fit(X_train, y_train)\n",
    "    y_pred = regressor.predict(X_test)\n",
    "    rmse.append(np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    if np.sqrt(metrics.mean_squared_error(y_test, y_pred)) < menor:\n",
    "        menor = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "        valor = estimator\n",
    "print(valor,menor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Crear un grafíco que permita visualizar el RMSE obtenido según el <code>n_estimator</code>?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fda59aba550>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fda59b57198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Ejemplo de Uso de Random Forest para la Clasificación\n",
    "\n",
    "#### Definición del problema\n",
    "\n",
    "La tarea aquí es predecir si un billete de banco es auténtico o no basándose en cuatro atributos: la variación de la imagen transformada en ondas, la asimetría, la entropía y la curtosis de la imagen.\n",
    "\n",
    "#### Solución\n",
    "\n",
    "Este es un problema de clasificación binaria y usaremos un clasificador Random Forest para resolver este problema. Los pasos que se sigan para resolver este problema serán similares a los pasos que se realicen para la regresión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a - Importar y Preparar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variance</th>\n",
       "      <th>Skewness</th>\n",
       "      <th>Curtosis</th>\n",
       "      <th>Entropy</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.6661</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.1674</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.6383</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.5228</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.4552</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variance  Skewness  Curtosis  Entropy  Class\n",
       "0   3.62160    8.6661   -2.8073 -0.44699      0\n",
       "1   4.54590    8.1674   -2.4586 -1.46210      0\n",
       "2   3.86600   -2.6383    1.9242  0.10645      0\n",
       "3   3.45660    9.5228   -4.0112 -3.59440      0\n",
       "4   0.32924   -4.4552    4.5718 -0.98880      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CARGAR EL DATASET\n",
    "\n",
    "import pandas as pd  \n",
    "import numpy as np \n",
    "\n",
    "dataset = pd.read_csv('bill_authentication.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La información detallada sobre los datos está disponible en el siguiente enlace:\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/banknote+authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir Features y Labels\n",
    "X = dataset.iloc[:, 0:4].values  \n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>b - Entrenamiento</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=20, random_state=0)  \n",
    "classifier.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En caso de regresión utilizamos la clase <code>RandomForestRegressor</code> de la biblioteca sklearn.ensemble. Para la clasificación, usaremos la clase <code>RandomForestClassifier</code> de la biblioteca sklearn.ensemble. La clase <code>RandomForestClassifier</code> también toma <code>n_estimadores</code> como parámetro. Como antes, este parámetro define el número de árboles en nuestro bosque aleatorio. Empezaremos con 20 árboles de nuevo. Puede encontrar detalles de todos los parámetros del RandomForestClassifier <a href=\"http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">aquí</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> c - Evaluación del modelo </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para los problemas de clasificación, las métricas utilizadas para evaluar un algoritmo son la exactitud, la matriz de confusión, los puntajes de precisión y recall y los valores F1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        410       0.00      0.00      0.00         1\n",
      "        457       0.00      0.00      0.00         0\n",
      "        464       0.00      0.00      0.00         0\n",
      "        467       0.00      0.00      0.00         1\n",
      "        487       0.00      0.00      0.00         1\n",
      "        508       0.00      0.00      0.00         0\n",
      "        534       0.00      0.00      0.00         1\n",
      "        540       0.00      0.00      0.00         0\n",
      "        547       0.00      0.00      0.00         0\n",
      "        571       0.00      0.00      0.00         1\n",
      "        577       0.00      0.00      0.00         2\n",
      "        580       0.00      0.00      0.00         1\n",
      "        587       0.00      0.00      0.00         1\n",
      "        610       0.00      0.00      0.00         0\n",
      "        628       0.00      0.00      0.00         0\n",
      "        704       0.00      0.00      0.00         1\n",
      "\n",
      "avg / total       0.00      0.00      0.00        10\n",
      "\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))  \n",
    "print(classification_report(y_test,y_pred))  \n",
    "print(accuracy_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. TP: Random Forest\n",
    "\n",
    "1) Encontrar un dataset que les interesa (ver por ejemplo <a href=\"https://www.kaggle.com/datasets\"> Kaggle</a> o <a href=\"https://github.com/awesomedata/awesome-public-datasets\">Awesome public datasets</a>...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "diab = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Describir un problema de clasificación asociado a este dataset, que se podría resolver con un enfoque de aprendizaje supervisado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se debe determinar si una persona tiene diabetes o no, dependiendo algunas caracteristicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Entrenar y evaluar un modelo Random Forest y compararlo con Decision Tree y Naive Bayes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_solito = DecisionTreeClassifier()\n",
    "arbolitos_juntos = RandomForestClassifier()\n",
    "nb = GaussianNB()\n",
    "X_train, X_test, y_train, y_test = train_test_split(diab.data, diab.target, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "arbol_solito.fit(X_train,y_train)\n",
    "arbolitos_juntos.fit(X_train,y_train)\n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "tree_pred = arbol_solito.predict(X_test)\n",
    "rf_pred = arbolitos_juntos.predict(X_test)\n",
    "nb_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Describir los resultados obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.85      0.87        27\n",
      "          1       0.91      0.86      0.88        35\n",
      "          2       0.84      0.89      0.86        36\n",
      "          3       0.70      0.90      0.79        29\n",
      "          4       0.93      0.87      0.90        30\n",
      "          5       0.87      0.85      0.86        40\n",
      "          6       0.91      0.93      0.92        44\n",
      "          7       0.93      0.97      0.95        39\n",
      "          8       0.79      0.67      0.72        39\n",
      "          9       0.85      0.83      0.84        41\n",
      "\n",
      "avg / total       0.86      0.86      0.86       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DecisionTreeClassifier\")\n",
    "print(classification_report(y_test,tree_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      1.00      0.95        27\n",
      "          1       0.85      0.97      0.91        35\n",
      "          2       0.97      0.92      0.94        36\n",
      "          3       0.87      0.93      0.90        29\n",
      "          4       1.00      0.97      0.98        30\n",
      "          5       0.97      0.93      0.95        40\n",
      "          6       1.00      0.95      0.98        44\n",
      "          7       0.95      1.00      0.97        39\n",
      "          8       0.97      0.87      0.92        39\n",
      "          9       0.93      0.90      0.91        41\n",
      "\n",
      "avg / total       0.94      0.94      0.94       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"RandomForestClassifier\")\n",
    "print(classification_report(y_test,rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        27\n",
      "          1       0.66      0.89      0.76        35\n",
      "          2       0.94      0.47      0.63        36\n",
      "          3       0.89      0.83      0.86        29\n",
      "          4       1.00      0.73      0.85        30\n",
      "          5       0.97      0.88      0.92        40\n",
      "          6       1.00      1.00      1.00        44\n",
      "          7       0.74      1.00      0.85        39\n",
      "          8       0.54      0.82      0.65        39\n",
      "          9       0.96      0.63      0.76        41\n",
      "\n",
      "avg / total       0.87      0.82      0.83       360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GaussianNB\")\n",
    "print(classification_report(y_test,nb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en este caso, RandomForest nos entrega un mejor resultado en los parametros probabilisticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
